{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import time\n",
    "\n",
    "sys.path.append('../../../')\n",
    "from utils import modelling as mod\n",
    "from utils import utils\n",
    "from utils import paths\n",
    "import wandb\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import KFold, cross_val_score, cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('/Users/tudor/Documents/phd/coding/project_CF/data/final_df_aberdeen.csv')\n",
    "df = pd.read_csv('/gws/nopw/j04/ai4er/users/ts809/era5_final/final_df_aberdeen.csv')    # JASMIN\n",
    "\n",
    "weights = mod.CalcClassWeights(df['floods'])\n",
    "df_to_analyse = df.drop(columns=['Unnamed: 0.1', 'time', 'Unnamed: 0', 'floods', 'time_ok', 't'])\n",
    "\n",
    "X = df_to_analyse.drop(columns=['floods_x4'])\n",
    "y = df_to_analyse['floods_x4']\n",
    "\n",
    "X_train = X.iloc[0:int(len(X) *.8)] \n",
    "X_test = X.iloc[int(len(X) *.8):int(len(X) *.9)]\n",
    "X_val = X.iloc[int(len(X) *.9):]\n",
    "\n",
    "y_train = y.iloc[0:int(len(y) *.8)]\n",
    "y_test = y.iloc[int(len(y) *.8):int(len(y) *.9)]\n",
    "y_val = y.iloc[int(len(y) *.9):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_val = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dectree = DecisionTreeClassifier(\n",
    "    criterion = 'gini',\n",
    "    splitter='best',\n",
    "    max_depth=None,\n",
    "    min_samples_split = 50,\n",
    "    min_samples_leaf= 1,\n",
    "    max_features='sqrt',\n",
    "    random_state=42,\n",
    "    class_weight=weights,\n",
    ")\n",
    "\n",
    "\t# criterion: gini\n",
    "\t# max_depth: None\n",
    "\t# max_features: sqrt\n",
    "\t# min_samples_leaf: 1\n",
    "\t# min_samples_split: 50\n",
    "\t# scaler: minmax\n",
    "\t# splitter: best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = KFold(n_splits = 4, shuffle=False)\n",
    "\n",
    "# start = time.time()\n",
    "\n",
    "cv_scores = cross_validate(dectree, X_train, y_train, cv=cv, \n",
    "                        scoring=('balanced_accuracy', 'jaccard', 'roc_auc_ovr', 'neg_log_loss'),\n",
    "                        n_jobs=4,\n",
    "                        error_score='raise',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['fit_time', 'score_time', 'test_balanced_accuracy', 'test_jaccard', 'test_roc_auc_ovr', 'test_neg_log_loss'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.5053022143248644)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(cv_scores.keys())\n",
    "interm = time.time()\n",
    "BA_score = cv_scores['test_balanced_accuracy'].mean()\n",
    "JAC_score = cv_scores['test_jaccard'].mean()\n",
    "AUC_score = cv_scores['test_roc_auc_ovr'].mean()\n",
    "CE_score = cv_scores['test_neg_log_loss'].mean()\n",
    "\n",
    "BA_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = dectree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4999571183533448"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "balanced_accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_CF",
   "language": "python",
   "name": "project_cf"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
